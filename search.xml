<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>VUE3</title>
      <link href="/2023/04/25/vue3/"/>
      <url>/2023/04/25/vue3/</url>
      
        <content type="html"><![CDATA[<h1 id="VUE模板语法"><a href="#VUE模板语法" class="headerlink" title="VUE模板语法"></a>VUE模板语法</h1><p>1.插值语法</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;span&gt;Message: &#123;&#123; msg &#125;&#125;&lt;/span&gt;</span><br></pre></td></tr></table></figure><p>msg是js中的表达式。一般可以通过插值来动态设置文本</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;template&gt;</span><br><span class="line">    &lt;p&gt;&#123;&#123;msg&#125;&#125;&lt;/p&gt;</span><br><span class="line">&lt;/template&gt;</span><br><span class="line"></span><br><span class="line">&lt;script&gt;</span><br><span class="line">    data()&#123;</span><br><span class="line">        return&#123;</span><br><span class="line">            msg:&quot;xxx&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure><p>2.原始HTML<br>双大括号只能解释成普通文本，需要用<strong>v-html</strong>输出html数据比如超链接</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;template&gt;</span><br><span class="line">    &lt;div v-html=&quot;rawhtml&quot;&gt;&lt;/div&gt;</span><br><span class="line">&lt;/template&gt;</span><br><span class="line"></span><br><span class="line">&lt;script&gt;</span><br><span class="line">    data()&#123;</span><br><span class="line">        return&#123;</span><br><span class="line">            rawhtml:&quot;&lt;a href=&#x27;http://xxxxx.com&#x27;&gt;标签&lt;/a&gt;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure><p>3.属性Attribute<br>双大括号不能再HTML属性中使用，要使用<strong>v-bind</strong>指令</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;template&gt;</span><br><span class="line">    &lt;div v-bind:id=&#x27;dynamicID&#x27;&gt;&lt;/div&gt;</span><br><span class="line">&lt;/template&gt;</span><br><span class="line"></span><br><span class="line">&lt;script&gt;</span><br><span class="line">    data()&#123;</span><br><span class="line">        return&#123;</span><br><span class="line">            dynamicID:1001</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure><blockquote><p>v-bind：可以简写为 ：</p></blockquote><p>4.使用JS表达式</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;template&gt;</span><br><span class="line">    &lt;p&gt;&#123;&#123; num+10 &#125;&#125;&lt;/p&gt;</span><br><span class="line">&lt;/template&gt;</span><br><span class="line"></span><br><span class="line">&lt;script&gt;</span><br><span class="line">    data()&#123;</span><br><span class="line">        return&#123;</span><br><span class="line">            num:10</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure><p>页面中就会返回一个20<br><strong>注意</strong>：只能是<strong>单个</strong>表达式</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;var a = 1&#125;&#125;</span><br></pre></td></tr></table></figure><p>这是语句所以不行</p><h1 id="响应式基础"><a href="#响应式基础" class="headerlink" title="响应式基础"></a>响应式基础</h1><p>1.要用到data选项来申明响应式的状态</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;script&gt;</span><br><span class="line">    data()&#123;</span><br><span class="line">        return&#123;</span><br><span class="line">            num:1</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure><p>2.声明方法要用到methods选项</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;script&gt;</span><br><span class="line">    data()&#123;</span><br><span class="line">        return&#123;</span><br><span class="line">            num:1</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;，</span><br><span class="line">    methods：&#123;</span><br><span class="line">        increment()&#123;</span><br><span class="line">            this.num++</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure><p>this永远指向组件实例<br>方法也和数据一样能够被模板访问</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;button @click=&quot;increment&quot;&gt;&#123;&#123; num &#125;&#125;&lt;/button&gt;</span><br></pre></td></tr></table></figure><p>increment方法会在button被点击的时候触发</p><h1 id="计算属性"><a href="#计算属性" class="headerlink" title="计算属性"></a>计算属性</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">export default &#123;</span><br><span class="line">  data() &#123;</span><br><span class="line">    return &#123;</span><br><span class="line">      author: &#123;</span><br><span class="line">        name: &#x27;John Doe&#x27;,</span><br><span class="line">        books: [</span><br><span class="line">          &#x27;Vue 2 - Advanced Guide&#x27;,</span><br><span class="line">          &#x27;Vue 3 - Basic Guide&#x27;,</span><br><span class="line">          &#x27;Vue 4 - The Mystery&#x27;</span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;p&gt;Has published books:&lt;/p&gt;</span><br><span class="line">&lt;span&gt;&#123;&#123; author.books.length &gt; 0 ? &#x27;Yes&#x27; : &#x27;No&#x27; &#125;&#125;&lt;/span&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">export default &#123;</span><br><span class="line">  data() &#123;</span><br><span class="line">    return &#123;</span><br><span class="line">      author: &#123;</span><br><span class="line">        name: &#x27;John Doe&#x27;,</span><br><span class="line">        books: [</span><br><span class="line">          &#x27;Vue 2 - Advanced Guide&#x27;,</span><br><span class="line">          &#x27;Vue 3 - Basic Guide&#x27;,</span><br><span class="line">          &#x27;Vue 4 - The Mystery&#x27;</span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  computed: &#123;</span><br><span class="line">    // 一个计算属性的 getter</span><br><span class="line">    publishedBooksMessage() &#123;</span><br><span class="line">      // `this` 指向当前组件实例</span><br><span class="line">      return this.author.books.length &gt; 0 ? &#x27;Yes&#x27; : &#x27;No&#x27;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;p&gt;Has published books:&lt;/p&gt;</span><br><span class="line">&lt;span&gt;&#123;&#123; publishedBooksMessage &#125;&#125;&lt;/span&gt;</span><br></pre></td></tr></table></figure><p>publishedBooksMessage是一个计算属性，会随着books数组的改变而改变</p><h1 id="类与样式绑定"><a href="#类与样式绑定" class="headerlink" title="类与样式绑定"></a>类与样式绑定</h1><p>1.绑定HTML class</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;div :class=&quot;&#123; active: isActive &#125;&quot;&gt;&lt;/div&gt;</span><br></pre></td></tr></table></figure><p>active是否存在取决于isActive的真假值</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;div</span><br><span class="line">  class=&quot;static&quot;</span><br><span class="line">  :class=&quot;&#123; active: isActive, &#x27;text-danger&#x27;: hasError &#125;&quot;</span><br><span class="line">&gt;&lt;/div&gt;</span><br></pre></td></tr></table></figure><p>data状态：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data() &#123;</span><br><span class="line">  return &#123;</span><br><span class="line">    isActive: true,</span><br><span class="line">    hasError: false</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果会变成：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;div class=&quot;static active&quot;&gt;&lt;/div&gt;</span><br></pre></td></tr></table></figure><p>2.绑定数组</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;div :class=&quot;[activeClass, errorClass]&quot;&gt;&lt;/div&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data() &#123;</span><br><span class="line">  return &#123;</span><br><span class="line">    activeClass: &#x27;active&#x27;,</span><br><span class="line">    errorClass: &#x27;text-danger&#x27;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="条件渲染"><a href="#条件渲染" class="headerlink" title="条件渲染"></a>条件渲染</h1><p><strong>v-if</strong>指令的内容只会在表达式返回true时被渲染</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;p v-if=&quot;flag&quot;&gt;xxx&lt;/p&gt;</span><br><span class="line"></span><br><span class="line">data()&#123;</span><br><span class="line">    return&#123;</span><br><span class="line">        flag:true</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样页面中就会渲染出xxx</p><p><strong>v-else</strong>if的else块，如果flag为flase就显示else的内容</p><p><strong>v-show</strong>与<strong>v-if</strong>的区别：<br>v-show会在DOM渲染中保留该元素（隐藏），v-show仅切换了该元素上的display的css属性v-show不支持再<template>袁术上使用，也不能与v-else搭配。<br>v-if会在false时直接把元素删除。<br>v-if有较高的切换开销，v-show有较高的初始渲染开销</p><h1 id="列表渲染"><a href="#列表渲染" class="headerlink" title="列表渲染"></a>列表渲染</h1><p>v-for把一个数组显示在页面上<br>语法：item in items<br>items是源数据数组，item是元素</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&lt;ul&gt;</span><br><span class="line">    &lt;li v-for=&quot;item in newsList&quot;&gt;</span><br><span class="line">        &#123;&#123; item.title &#125;&#125;</span><br><span class="line">    &lt;/li&gt;</span><br><span class="line">&lt;/ul&gt;</span><br><span class="line">data()&#123;</span><br><span class="line">    return&#123;</span><br><span class="line">        newsList:[</span><br><span class="line">            &#123;</span><br><span class="line">                id:01,</span><br><span class="line">                title:&quot;news1&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                id:02,</span><br><span class="line">                title:&quot;news2&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                id:03,</span><br><span class="line">                title:&quot;news3&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>数组增加元素后只需要渲染新增的数据</strong>需要增加唯一的ID</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;li v-for=&quot;item in newsList&quot; :key=&quot;item.id&quot;&gt;</span><br><span class="line">        &#123;&#123; item.title &#125;&#125;</span><br><span class="line">    &lt;/li&gt;</span><br></pre></td></tr></table></figure><h1 id="事件处理"><a href="#事件处理" class="headerlink" title="事件处理"></a>事件处理</h1><p>1.监听事件（添加事件）<br><strong>v-on</strong>（通常缩写为@）来监听DOM事件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;button @click=&quot;counter +=1&quot;&gt;Add 1：counter = &#123;&#123; counter &#125;&#125;&lt;/button&gt;</span><br><span class="line"></span><br><span class="line">data()&#123;</span><br><span class="line">    return&#123;</span><br><span class="line">        counter:0</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述代码标识点一下按钮counter就加一<br>2.事件处理方法</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;button @click=&quot;clickHandle&quot;&gt;按钮&lt;/button&gt;</span><br><span class="line"></span><br><span class="line">data()&#123;</span><br><span class="line">    return&#123;</span><br><span class="line">        message:&quot;1&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">methods:&#123;</span><br><span class="line">    clickHandle(event)&#123;</span><br><span class="line">        console.log(&quot;hhh&quot;);</span><br><span class="line">        this.message = &quot;2&quot;;</span><br><span class="line">        console.log(event);</span><br><span class="line">        event.target.innerHTML = &quot;点击&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以通过函数执行JS代码也可以改变页面中的内容<br><strong>event</strong>是原生DOM的event（事件对象）<br><strong>event.target.innerHTML</strong>可以将按钮上的字改变<br>3.事件传递参数</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;button @click=&quot;say（hi）&quot;&gt;say hi&lt;/button&gt;</span><br><span class="line">&lt;button @click=&quot;say（what）&quot;&gt;say what&lt;/button&gt;</span><br><span class="line">methods:&#123;</span><br><span class="line">    say(data)&#123;</span><br><span class="line">        console.log(data);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>data就是传递过来的参数</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;ul&gt;</span><br><span class="line">    &lt;li @click=&quot;clickItemHandle(item)&quot; v-for=&quot;(item,index) in names&quot; :key=&quot;index&quot;&gt;&#123;&#123; item &#125;&#125;&lt;/li&gt;</span><br><span class="line">&lt;/ul&gt;</span><br><span class="line"></span><br><span class="line">data()&#123;</span><br><span class="line">    return&#123;</span><br><span class="line">        names:[&quot;jack&quot;,&quot;tom&quot;,&quot;mara&quot;]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;,</span><br><span class="line">methods:&#123;</span><br><span class="line">    clickItemHandle(item)&#123;</span><br><span class="line">        console.log(item);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述操作传递了列表中的参数</p><h1 id="表单输入绑定"><a href="#表单输入绑定" class="headerlink" title="表单输入绑定"></a>表单输入绑定</h1><p><strong>v-model</strong>指令监听用户输入数据的更新</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;input type=&quot;text&quot; v-model=&quot;username&quot;&gt;</span><br><span class="line">&lt;p&gt;&#123;&#123; username &#125;&#125;&lt;/p&gt;</span><br><span class="line">data()&#123;</span><br><span class="line">    return&#123;</span><br><span class="line">        username:&quot;&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在输入的同时会在页面上显示输入的内容（双向数据绑定）</p><p>修饰符：<br>.lazy<br>v-model在每次input事件触发后都会将输入框的值与数据进行同步，加了lazy修饰符后会转为在change事件后同步。（回车后）<br>v-model.lazy</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>人工智能算法学习</title>
      <link href="/2023/04/23/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AE%97%E6%B3%95/"/>
      <url>/2023/04/23/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="循环神经网络（RNN）"><a href="#循环神经网络（RNN）" class="headerlink" title="循环神经网络（RNN）"></a>循环神经网络（RNN）</h1><blockquote><p>RNN对具有序列特性的数据非常有效，它能挖掘数据中的时序信息以及语义信息。<strong>序列特性</strong>就是符合时间顺序，逻辑顺序，或者其他顺序。<br>例子：一个人说的一句话是符合某个逻辑的字词拼接起来的。</p></blockquote><h3 id="发明循环神经网络的原因"><a href="#发明循环神经网络的原因" class="headerlink" title="发明循环神经网络的原因"></a>发明循环神经网络的原因</h3><p>I like eating apple！<br>The Apple is a great company！<br>两句话我们能看出两个Apple有不同的意义。当使用全连接神经网络时我们会给不同的APPLE打上label（标签）然后将apple的特征向量输入到如下的模型中</p><blockquote><p>特征向量：矩阵的特征向量是矩阵理论上的重要概念之一，它有着广泛的应用。数学上，线性变换的特征向量（本征向量）是一个非简并的向量，其方向在该变换下不变。该向量在此变换下缩放的比例称为其特征值（本征值）。<br><img src="/img/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.jpeg" alt="这是图片" title="Magic Gardens"><br>输出结果时，让我们的Label里，正确的Label概率最大。但是因为我们的库中的Apple有不同的意思这就导致预测的准确程度取决于训练集中的哪个Label多一点，所以这就对我们没有一点用。<strong>问题就出在没有结合上下文训练模型，于是就出现了循环神经网络</strong></p></blockquote><h3 id="循环神经网络的结构和原理"><a href="#循环神经网络的结构和原理" class="headerlink" title="循环神经网络的结构和原理"></a>循环神经网络的结构和原理</h3><p><img src="/img/RNN%E7%AE%80%E5%8D%95%E7%BB%93%E6%9E%84.jpg" alt="这是图片" title="Magic Gardens"><br>这是简单的RNN结构。这和上面的全神经网络看着很不一样。<br>但是当我们先不管右边的W，只看左边的X,U,S,V,O时这幅图就会变成和上面全神经网络的图一模一样，X是某个特征向量，作为输入层，U是输入层到隐藏层的参数矩阵，S是隐藏层的向量，V是隐藏层到输出层的参数矩阵，O是输出层的向量。<br>接下来我们看看右边的W。上面的图按照时间线展开后变成了这样：<br><img src="/img/RNN%E5%B1%95%E5%BC%80%E7%BB%93%E6%9E%84.jpg" alt="这是图片" title="Magic Gardens"><br>举个例子：有一句话，I love you那么上图的<em>X</em><sub>t-1</sub>代表I的向量，<em>X</em>代表love的向量，<em>X</em><sub>t+1</sub>代表you的向量。我们注意到W一直没变，其实<strong>W是每个时间点的权重矩阵</strong>。而RNN能解决序列问题，<strong>是因为它可以记住每一时刻的信息，每一时刻的隐藏层不仅由该时刻的输入层决定，还由上一时刻的隐藏层决定</strong>，公式如下，其中O<sub>t</sub>代表t时刻的输出，S<sub>t</sub>代表t时刻隐藏层的值：<br><img src="/img/RNN%E7%AE%97%E6%B3%95%E5%85%AC%E5%BC%8F.png" alt="这是图片" title="Magic Gardens"><br>g和f为激活函数</p><blockquote><p>激活函数（Activation Function）是一种添加到人工神经网络中的函数，旨在帮助网络学习数据中的复杂模式。在神经元中，输入的input经过一系列加权求和后作用于另一个函数，这个函数就是这里的激活函数<br>为什么要使用激活函数？因为神经网络中每一层的输入输出都是一个线性求和的过程，下一层的输出只是承接了上一层输入函数的线性变换，所以如果没有激活函数，那么无论你构造的神经网络多么复杂，有多少层，最后的输出都是输入的线性组合，纯粹的线性组合并不能够解决更为复杂的问题。而引入激活函数之后，我们会发现常见的激活函数都是非线性的，因此也会给神经元引入非线性元素，使得神经网络可以逼近其他的任何非线性函数，这样可以使得神经网络应用到更多非线性模型中。</p></blockquote><h3 id="实现RNN的代码"><a href="#实现RNN的代码" class="headerlink" title="实现RNN的代码"></a>实现RNN的代码</h3><p>pytorch中RNN模块函数torch.nn.RNN<br>参数：<br><strong>input_size</strong>:输入数据的编码维度<br><strong>hiddensize</strong>：隐含层的维数（通常为20）<br><strong>num_layers</strong>:隐含层的层数（一般来说，层数越多，整个网络的误差也就越小，但是会是整个网络复杂化，增加网络的训练时间，也有可能出现“过拟合”（太适应于训练集，在测试集上效果不好）的情况。一般来说，一两层的隐藏层已经能够解决很多问题了，如果数据量多，可以在防止出现过拟合的情况下适当的增加层数。）<br><strong>batch_first</strong>：当 batch_first设置为True时，输入的参数顺序变为：x：[batch, seq_len, input_size]，h0：[batch, num_layers, hidden_size]。<br>使用实例：<br>比如我现在想设计一个4层的RNN，用来做语音翻译，输入是一段中文，输出是一段英文。假设每个中文字符用100维数据进行编码，每个隐含层的维度是20，有4个隐含层。所以input_size = 100，hidden_size = 20，num_layers = 4。再假设模型已经训练好了，现在有个1个长度为10的句子做输入，那么seq_len = 10，batch_size = 1。代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">input_size = <span class="number">100</span>   <span class="comment"># 输入数据编码的维度</span></span><br><span class="line">hidden_size = <span class="number">20</span>   <span class="comment"># 隐含层维度</span></span><br><span class="line">num_layers = <span class="number">4</span>     <span class="comment"># 隐含层层数</span></span><br><span class="line"></span><br><span class="line">rnn = nn.RNN(input_size=input_size,hidden_size=hidden_size,num_layers=num_layers)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;rnn:&quot;</span>,rnn)</span><br><span class="line"></span><br><span class="line">seq_len = <span class="number">10</span>        <span class="comment"># 句子长度</span></span><br><span class="line">batch_size = <span class="number">1</span>      </span><br><span class="line">x = torch.randn(seq_len,batch_size,input_size)        <span class="comment"># 输入数据</span></span><br><span class="line">h0 = torch.zeros(num_layers,batch_size,hidden_size)   <span class="comment"># 输入数据</span></span><br><span class="line"></span><br><span class="line">out, h = rnn(x, h0)  <span class="comment"># 输出数据</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;out.shape:&quot;</span>,out.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;h.shape:&quot;</span>,h.shape)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>传统RNN的优势：由于内部结构简单, 对计算资源要求低, 相比之后我们要学习的RNN变体:LSTM和GRU模型参数总量少了很多, 在短序列任务上性能和效果都表现优异.<br>缺点：传统RNN在解决长序列之间的关联时, 通过实践，证明经典RNN表现很差, 原因是在进行反向传播的时候, 过长的序列导致梯度的计算异常, 发生梯度消失或爆炸.</p><h1 id="长短期记忆网络（LSTM）"><a href="#长短期记忆网络（LSTM）" class="headerlink" title="长短期记忆网络（LSTM）"></a>长短期记忆网络（LSTM）</h1><blockquote><p>LSTM是RNN的一种变体，可以解决长期记忆问题。</p></blockquote><h3 id="什么是LSTM"><a href="#什么是LSTM" class="headerlink" title="什么是LSTM"></a>什么是LSTM</h3><p>RNN在对短时间序列数据的分析时十分方便，但是它有长期依赖问题：RNN只能处理较接近的上下文的情况。而且RNN还会有梯度消失（神经网络的权重/偏置梯度极小，导致神经网络参数调整速率急剧下降）和梯度爆炸（神经网络的权重/偏置梯度极大，导致神经网络参数调整幅度过大，矫枉过正）问题</p><h3 id="为什么需要LSTM"><a href="#为什么需要LSTM" class="headerlink" title="为什么需要LSTM"></a>为什么需要LSTM</h3><p>LSTM从被设计之初就被用于解决一般递归神经网络中普遍存在的长期依赖问题，使用LSTM可以有效的传递和表达长时间序列中的信息并且不会导致长时间前的有用信息被忽略（遗忘）。与此同时，LSTM还可以解决RNN中的梯度消失/爆炸问题。</p><h3 id="解释LSTM"><a href="#解释LSTM" class="headerlink" title="解释LSTM"></a>解释LSTM</h3><p>一个普通的RNN：<br><img src="/img/RNN%E7%BB%93%E6%9E%84.png" alt="这是图片" title="Magic Gardens"><br>可以看到A在t-1时刻的输出值h<sub>t-1</sub>被复制到了t时刻，与t时刻的输入x<sub>t</sub>整合后结果一个带权重和偏置的tanh函数后形成输出，并继续将数据复制到t+1时刻<br>如下是LSTM的结构：<br><img src="/img/LSTM%E7%BB%93%E6%9E%84.png" alt="这是图片" title="Magic Gardens"><br>可以看出每个LSTM单元有更加复杂的内部结构和输入输出，在上图中，每一个红色圆形代表对向量做出的操作（pointwise operation，对位操作），而黄色的矩形代表一个神经网络层，上面的字符代表神经网络所使用的激活函数</p><blockquote><p>point-wise operation 对位操作<br>如果我要对向量&lt;1, 2, 3&gt; 和 &lt;1, 3, 5&gt;进行逐分量的想成操作，会获得结果 &lt;1, 6, 15&gt;<br>layer 函数层<br>一个函数层拥有两个属性：权重向量(Weight) 和 偏置向量(bias)，对于输入向量A的每一个分量i，函数层会对其进行以下操作：output<sub>i</sub>=F（W<sub>i</sub>*A<sub>i</sub>+b<sub>i</sub>）常见的激活函数有ReLU（线性修正单元），sigmoid（kesai）和tanh</p></blockquote><p>LSTM区别于RNN最大的优势就是上图中从单元中贯穿而过的线-神经元的隐藏态（单元状态），我们可以将神经元的隐藏态简单的理解成递归神经网络对于输入数据的“记忆”，用C<sub>t</sub>表示神经元在t时刻过后的“记忆”，这个向量涵盖了在t+1时刻前神经网络对于所有输入信息的“概括总结”<br><img src="/img/LSTM%E5%8D%95%E5%85%83%E7%8A%B6%E6%80%81.jpg" alt="这是图片" title="Magic Gardens"><br>接下来看一下LSTM四个函数层分别在干什么：<br><strong>LSTM_1 遗忘门</strong><br><img src="/img/LSTM%E9%81%97%E5%BF%98%E9%97%A8.jpg" alt="这是图片" title="Magic Gardens"><br>对于上一时刻LSTM中的单元状态来说，一些“信息”可能会随着时间的流逝而“过时”。为了不让过多记忆影响神经网络对现在输入的处理，我们应该选择性遗忘一些在之前单元状态中的分量——这个工作就交给了“遗忘门”<br>每一次输入一个新的输入，LSTM会先根据新的输入和上一时刻的输出决定遗忘掉之前的哪些记忆——输入和上一步的输出会整合为一个单独的向量，然后通过sigmoid神经层，最后点对点的乘在单元状态上。因为sigmoid 函数会将任意输入压缩到（0，1）的区间上，我们可以非常直觉的得出这个门的工作原理 —— 如果整合后的向量某个分量在通过sigmoid层后变为0，那么显然单元状态在对位相乘后对应的分量也会变成0，换句话说，“遗忘”了这个分量上的信息；如果某个分量通过sigmoid层后为1，单元状态会“保持完整记忆”。不同的sigmoid输出会带来不同信息的记忆与遗忘。通过这种方式，LSTM可以<strong>长期记忆重要信息</strong>，并且<strong>记忆可以随着输入进行动态调整</strong><br>下面的公式就是遗忘门的计算：<br><img src="/img/LSTM%E9%81%97%E5%BF%98%E9%97%A8%E8%AE%A1%E7%AE%97.png" alt="这是图片" title="Magic Gardens"></p><p><strong>LSTM_2&amp;3 记忆门</strong><br><img src="/img/LSTM%E8%AE%B0%E5%BF%86%E9%97%A8.jpg" alt="这是图片" title="Magic Gardens"><br>记忆门是用来控制是否将在t时刻（现在）的数据并入单元状态中的控制单位。首先，用tanh函数层将现在的向量中的有效信息提取出来，然后使用（图上tanh函数层左侧）的sigmoid函数来控制这些记忆要放“多少”进入单元状态。这两者结合起来就可以做到：<br>1.从当前输入中提取有效信息<br>2.对提取的有效信息做出筛选，为每个分量做出评级(0 ~ 1)，评级越高的最后会有越多的记忆进入单元状态<br>下面的公式分别为这两个步骤在LSTM中的计算<br><img src="/img/LSTM%E8%AE%B0%E5%BF%86%E9%97%A8%E8%AE%A1%E7%AE%97.png" alt="这是图片" title="Magic Gardens"></p><p><strong>LSTM_4 输出门</strong><br>输出门，顾名思义，就是LSTM单元用于计算当前时刻的输出值的神经层。输出层会先将当前输入值与上一时刻输出值整合后的向量（也就是公式中的[h<sub>t-1</sub>,x<sub>t</sub>]）用sigmoid函数提取其中的信息，接着，会将当前的单元状态通过tanh函数压缩映射到区间(-1, 1)中</p><blockquote><p>为什么我们要在LSTM的输出门上使用tanh函数？<br>以下引用自Stack Overflow上问题 What is the intuition of using tanh in LSTM 中的最佳答案：<br><a href="https://stackoverflow.com/questions/40761185/what-is-the-intuition-of-using-tanh-in-lstm">https://stackoverflow.com/questions/40761185/what-is-the-intuition-of-using-tanh-in-lstm</a><br>在LSTM的输入和输出门中使用tanh函数有以下几个原因：</p></blockquote><ol><li>为了防止梯度消失问题，我们需要一个二次导数在大范围内不为0的函数，而tanh函数可以满足这一点</li><li>为了便于凸优化，我们需要一个单调函数</li><li>tanh函数一般收敛的更快</li><li>tanh函数的求导占用系统的资源更少<br>将经过tanh函数处理后的单元状态与sigmoid函数处理后的，整合后的向量点对点的乘起来就可以得到LSTM在t时刻的输出了！</li></ol><h3 id="基于pytorch的LSTM代码实现"><a href="#基于pytorch的LSTM代码实现" class="headerlink" title="基于pytorch的LSTM代码实现"></a>基于pytorch的LSTM代码实现</h3><p>我们取正弦函数的值作为LSTM的输入，来预测余弦函数的值。基于Pytorch来构建LSTM模型，采用1个输入神经元，1个输出神经元，16个隐藏神经元作为LSTM网络的构成参数，平均绝对误差（LMSE）作为损失误差，使用Adam优化算法来训练LSTM神经网络。基于Anaconda和Python3.6的完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LstmRNN</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Parameters：</span></span><br><span class="line"><span class="string">        - input_size: feature size</span></span><br><span class="line"><span class="string">        - hidden_size: number of hidden units</span></span><br><span class="line"><span class="string">        - output_size: number of output</span></span><br><span class="line"><span class="string">        - num_layers: layers of LSTM to stack</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size=<span class="number">1</span>, output_size=<span class="number">1</span>, num_layers=<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"> </span><br><span class="line">        self.lstm = nn.LSTM(input_size, hidden_size, num_layers) <span class="comment"># utilize the LSTM model in torch.nn </span></span><br><span class="line">        self.forwardCalculation = nn.Linear(hidden_size, output_size)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, _x</span>):</span><br><span class="line">        x, _ = self.lstm(_x)  <span class="comment"># _x is input, size (seq_len, batch, input_size)</span></span><br><span class="line">        s, b, h = x.shape  <span class="comment"># x is output, size (seq_len, batch, hidden_size)</span></span><br><span class="line">        x = x.view(s*b, h)</span><br><span class="line">        x = self.forwardCalculation(x)</span><br><span class="line">        x = x.view(s, b, -<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># create database</span></span><br><span class="line">    data_len = <span class="number">200</span></span><br><span class="line">    t = np.linspace(<span class="number">0</span>, <span class="number">12</span>*np.pi, data_len)</span><br><span class="line">    sin_t = np.sin(t)</span><br><span class="line">    cos_t = np.cos(t)</span><br><span class="line"></span><br><span class="line">    dataset = np.zeros((data_len, <span class="number">2</span>))</span><br><span class="line">    dataset[:,<span class="number">0</span>] = sin_t</span><br><span class="line">    dataset[:,<span class="number">1</span>] = cos_t</span><br><span class="line">    dataset = dataset.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># plot part of the original dataset</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.plot(t[<span class="number">0</span>:<span class="number">60</span>], dataset[<span class="number">0</span>:<span class="number">60</span>,<span class="number">0</span>], label=<span class="string">&#x27;sin(t)&#x27;</span>)</span><br><span class="line">    plt.plot(t[<span class="number">0</span>:<span class="number">60</span>], dataset[<span class="number">0</span>:<span class="number">60</span>,<span class="number">1</span>], label = <span class="string">&#x27;cos(t)&#x27;</span>)</span><br><span class="line">    plt.plot([<span class="number">2.5</span>, <span class="number">2.5</span>], [-<span class="number">1.3</span>, <span class="number">0.55</span>], <span class="string">&#x27;r--&#x27;</span>, label=<span class="string">&#x27;t = 2.5&#x27;</span>) <span class="comment"># t = 2.5</span></span><br><span class="line">    plt.plot([<span class="number">6.8</span>, <span class="number">6.8</span>], [-<span class="number">1.3</span>, <span class="number">0.85</span>], <span class="string">&#x27;m--&#x27;</span>, label=<span class="string">&#x27;t = 6.8&#x27;</span>) <span class="comment"># t = 6.8</span></span><br><span class="line">    plt.xlabel(<span class="string">&#x27;t&#x27;</span>)</span><br><span class="line">    plt.ylim(-<span class="number">1.2</span>, <span class="number">1.2</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;sin(t) and cos(t)&#x27;</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># choose dataset for training and testing</span></span><br><span class="line">    train_data_ratio = <span class="number">0.5</span> <span class="comment"># Choose 80% of the data for testing</span></span><br><span class="line">    train_data_len = <span class="built_in">int</span>(data_len*train_data_ratio)</span><br><span class="line">    train_x = dataset[:train_data_len, <span class="number">0</span>]</span><br><span class="line">    train_y = dataset[:train_data_len, <span class="number">1</span>]</span><br><span class="line">    INPUT_FEATURES_NUM = <span class="number">1</span></span><br><span class="line">    OUTPUT_FEATURES_NUM = <span class="number">1</span></span><br><span class="line">    t_for_training = t[:train_data_len]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># test_x = train_x</span></span><br><span class="line">    <span class="comment"># test_y = train_y</span></span><br><span class="line">    test_x = dataset[train_data_len:, <span class="number">0</span>]</span><br><span class="line">    test_y = dataset[train_data_len:, <span class="number">1</span>]</span><br><span class="line">    t_for_testing = t[train_data_len:]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ----------------- train -------------------</span></span><br><span class="line">    train_x_tensor = train_x.reshape(-<span class="number">1</span>, <span class="number">5</span>, INPUT_FEATURES_NUM) <span class="comment"># set batch size to 5</span></span><br><span class="line">    train_y_tensor = train_y.reshape(-<span class="number">1</span>, <span class="number">5</span>, OUTPUT_FEATURES_NUM) <span class="comment"># set batch size to 5</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment"># transfer data to pytorch tensor</span></span><br><span class="line">    train_x_tensor = torch.from_numpy(train_x_tensor)</span><br><span class="line">    train_y_tensor = torch.from_numpy(train_y_tensor)</span><br><span class="line">    <span class="comment"># test_x_tensor = torch.from_numpy(test_x)</span></span><br><span class="line"> </span><br><span class="line">    lstm_model = LstmRNN(INPUT_FEATURES_NUM, <span class="number">16</span>, output_size=OUTPUT_FEATURES_NUM, num_layers=<span class="number">1</span>) <span class="comment"># 16 hidden units</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;LSTM model:&#x27;</span>, lstm_model)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;model.parameters:&#x27;</span>, lstm_model.parameters)</span><br><span class="line"> </span><br><span class="line">    loss_function = nn.MSELoss()</span><br><span class="line">    optimizer = torch.optim.Adam(lstm_model.parameters(), lr=<span class="number">1e-2</span>)</span><br><span class="line"> </span><br><span class="line">    max_epochs = <span class="number">10000</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(max_epochs):</span><br><span class="line">        output = lstm_model(train_x_tensor)</span><br><span class="line">        loss = loss_function(output, train_y_tensor)</span><br><span class="line"> </span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">if</span> loss.item() &lt; <span class="number">1e-4</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Epoch [&#123;&#125;/&#123;&#125;], Loss: &#123;:.5f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch+<span class="number">1</span>, max_epochs, loss.item()))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;The loss value is reached&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">elif</span> (epoch+<span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Epoch: [&#123;&#125;/&#123;&#125;], Loss:&#123;:.5f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch+<span class="number">1</span>, max_epochs, loss.item()))</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># prediction on training dataset</span></span><br><span class="line">    predictive_y_for_training = lstm_model(train_x_tensor)</span><br><span class="line">    predictive_y_for_training = predictive_y_for_training.view(-<span class="number">1</span>, OUTPUT_FEATURES_NUM).data.numpy()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># torch.save(lstm_model.state_dict(), &#x27;model_params.pkl&#x27;) # save model parameters to files</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment"># ----------------- test -------------------</span></span><br><span class="line">    <span class="comment"># lstm_model.load_state_dict(torch.load(&#x27;model_params.pkl&#x27;))  # load model parameters from files</span></span><br><span class="line">    lstm_model = lstm_model.<span class="built_in">eval</span>() <span class="comment"># switch to testing model</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># prediction on test dataset</span></span><br><span class="line">    test_x_tensor = test_x.reshape(-<span class="number">1</span>, <span class="number">5</span>, INPUT_FEATURES_NUM) <span class="comment"># set batch size to 5, the same value with the training set</span></span><br><span class="line">    test_x_tensor = torch.from_numpy(test_x_tensor)</span><br><span class="line"> </span><br><span class="line">    predictive_y_for_testing = lstm_model(test_x_tensor)</span><br><span class="line">    predictive_y_for_testing = predictive_y_for_testing.view(-<span class="number">1</span>, OUTPUT_FEATURES_NUM).data.numpy()</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># ----------------- plot -------------------</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.plot(t_for_training, train_x, <span class="string">&#x27;g&#x27;</span>, label=<span class="string">&#x27;sin_trn&#x27;</span>)</span><br><span class="line">    plt.plot(t_for_training, train_y, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;ref_cos_trn&#x27;</span>)</span><br><span class="line">    plt.plot(t_for_training, predictive_y_for_training, <span class="string">&#x27;y--&#x27;</span>, label=<span class="string">&#x27;pre_cos_trn&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.plot(t_for_testing, test_x, <span class="string">&#x27;c&#x27;</span>, label=<span class="string">&#x27;sin_tst&#x27;</span>)</span><br><span class="line">    plt.plot(t_for_testing, test_y, <span class="string">&#x27;k&#x27;</span>, label=<span class="string">&#x27;ref_cos_tst&#x27;</span>)</span><br><span class="line">    plt.plot(t_for_testing, predictive_y_for_testing, <span class="string">&#x27;m--&#x27;</span>, label=<span class="string">&#x27;pre_cos_tst&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.plot([t[train_data_len], t[train_data_len]], [-<span class="number">1.2</span>, <span class="number">4.0</span>], <span class="string">&#x27;r--&#x27;</span>, label=<span class="string">&#x27;separation line&#x27;</span>) <span class="comment"># separation line</span></span><br><span class="line"></span><br><span class="line">    plt.xlabel(<span class="string">&#x27;t&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;sin(t) and cos(t)&#x27;</span>)</span><br><span class="line">    plt.xlim(t[<span class="number">0</span>], t[-<span class="number">1</span>])</span><br><span class="line">    plt.ylim(-<span class="number">1.2</span>, <span class="number">4</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line">    plt.text(<span class="number">14</span>, <span class="number">2</span>, <span class="string">&quot;train&quot;</span>, size = <span class="number">15</span>, alpha = <span class="number">1.0</span>)</span><br><span class="line">    plt.text(<span class="number">20</span>, <span class="number">2</span>, <span class="string">&quot;test&quot;</span>, size = <span class="number">15</span>, alpha = <span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">    </span><br></pre></td></tr></table></figure><p>如下为训练过程：<br><img src="/img/LSTM%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B.png" alt="这是图片" title="Magic Gardens"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>计网学习</title>
      <link href="/2023/04/12/%E8%AE%A1%E7%BD%91/"/>
      <url>/2023/04/12/%E8%AE%A1%E7%BD%91/</url>
      
        <content type="html"><![CDATA[<h1 id="计网学习"><a href="#计网学习" class="headerlink" title="计网学习"></a>计网学习</h1><h2 id="第一章-计算机网络和因特网"><a href="#第一章-计算机网络和因特网" class="headerlink" title="第一章 计算机网络和因特网"></a>第一章 计算机网络和因特网</h2><blockquote><p>目标：了解基本属于和概念、掌握网络的基本原理</p></blockquote><h3 id="1-1什么是Internet？"><a href="#1-1什么是Internet？" class="headerlink" title="1.1什么是Internet？"></a>1.1什么是Internet？</h3><h5 id="网络："><a href="#网络：" class="headerlink" title="网络："></a>网络：</h5><p>节点和边的关系</p><h5 id="计算机网络："><a href="#计算机网络：" class="headerlink" title="计算机网络："></a>计算机网络：</h5><p>联网的计算机系统。<br>包括主机节点（电脑、手机等）是数据的源和目标，数据交换节点（路由器、交换机等）数据中转的节点，<br>链路（连接节点）：接入链路（主机连到互联网），主干链路（路由器间的链路）</p><h5 id="互联网："><a href="#互联网：" class="headerlink" title="互联网："></a>互联网：</h5><p>从构成的角度看：包括了节点和边。是以TCP、IP协议为主支撑的用的人最多的网络。互联网标准：RFC、IETF。<br>从服务的角度看：是分布式应用以及为分布式应用提供通讯的基础设施（方式为API）。  </p><h5 id="协议："><a href="#协议：" class="headerlink" title="协议："></a>协议：</h5><p>不同层有不同协议。传输层：TCP，UDP 网络层：IP，路由选择协议 链路层物理层：…..<br>规范了语法（发请求的格式服从http）、语义（按规范解释报文）、时序（收完之后发）、动作（收、发）。  </p><blockquote><p>协议的定义：<strong>对等层</strong>的实体在通信的过程中应该遵循的规则的集合</p></blockquote><blockquote><p>网络结构：网络边缘（主机，应用程序）、网络核心（互联着的路由器，交换机）、接入网物理媒体（有线，无线通信链路）</p></blockquote><h3 id="1-2网络边缘："><a href="#1-2网络边缘：" class="headerlink" title="1.2网络边缘："></a>1.2网络边缘：</h3><h5 id="应用进程间的通信模式："><a href="#应用进程间的通信模式：" class="headerlink" title="应用进程间的通信模式："></a>应用进程间的通信模式：</h5><p>1.CS模式（客户端服务器模式）web 问题：可扩展性差，超载荷时能力断崖式下降<br>2.P2P模式（对等模式）迅雷 每个节点既是客户端也是服务器</p><h5 id="基础设施为网络应用提供的服务："><a href="#基础设施为网络应用提供的服务：" class="headerlink" title="基础设施为网络应用提供的服务："></a>基础设施为网络应用提供的服务：</h5><p>1.面向连接服务  两个应用进程的通信开始前先建立连接（握手）为后面的通信做好准备 如TCP服务（可靠的：发送的和收到的一样，流量控制：控制接收速度和发送速度，拥塞控制：在堵塞时让发送速度降低）<br>2.无连接服务    不用握手 如UDP服务（不可靠，没有流量控制和拥塞控制，把主机到主机细分为进程到进程，实时）</p><h3 id="1-3网络核心："><a href="#1-3网络核心：" class="headerlink" title="1.3网络核心："></a>1.3网络核心：</h3><h5 id="数据传输的方法："><a href="#数据传输的方法：" class="headerlink" title="数据传输的方法："></a>数据传输的方法：</h5><p><strong>电路交换</strong>：资源独享（保障了性能但会有资源浪费）网络资源被分成片（频分FDM、时分TDM、波分）   连接建立时间长，计算机之间的通信有突发性所以浪费情况严重，可靠性不高导致电路交换不适合计算机之间的通信。<br><strong>分组交换</strong>：主机的带宽资源不分成一个个的片，主机和主机间的通信数据分成一个个组，以组为单位在每个交换机中存储转发（不存储的化会占用线路）。<strong>缺点</strong>：在存储时需要排队。路由器的缓存用完时新来的分组会被抛弃。<strong>优点</strong>：线路可共享</p><h6 id="分组交换作用下的网络核心的关键功能："><a href="#分组交换作用下的网络核心的关键功能：" class="headerlink" title="分组交换作用下的网络核心的关键功能："></a>分组交换作用下的网络核心的关键功能：</h6><p><strong>转发</strong>：局部的将分组从路由器的输入链路转移到输出链路<br><strong>路由</strong>：全局的决定分组采用的源到目标的路径</p><h6 id="分组交换按网络层是否连接分类："><a href="#分组交换按网络层是否连接分类：" class="headerlink" title="分组交换按网络层是否连接分类："></a>分组交换按网络层是否连接分类：</h6><p>数据报方式：分组携带目标主机完整地址，不需要握手<br>虚电路：需要握手建立虚拟电路，每个分组按照虚电路号传输</p><h3 id="1-4接入网和物理媒体："><a href="#1-4接入网和物理媒体：" class="headerlink" title="1.4接入网和物理媒体："></a>1.4接入网和物理媒体：</h3><h5 id="接入方式："><a href="#接入方式：" class="headerlink" title="接入方式："></a>接入方式：</h5><p><strong>modem住宅接入（猫）</strong>电话线接入<br><strong>DSL</strong>电话线带宽一部分用来上网<br><strong>线缆网络</strong>对有线电视线缆进行改造和光纤一起接入，划分带宽用于不同用处<br><strong>无线接入网络</strong>无线LAN，无线局域接入</p><h5 id="物理媒体："><a href="#物理媒体：" class="headerlink" title="物理媒体："></a>物理媒体：</h5><p><strong>同轴电缆</strong>双向<br><strong>光纤光缆</strong>光脉冲，高速，低误码率（不受电磁波干扰），安全<br><strong>无线线缆</strong>无需物理“线缆”。类型：地面微波、LAN、广域无线（基站）、卫星</p><h3 id="1-5Internet结构和ISP"><a href="#1-5Internet结构和ISP" class="headerlink" title="1.5Internet结构和ISP"></a>1.5Internet结构和ISP</h3><blockquote><p>互联网络结构：网络的网络</p></blockquote><p><strong>端系统通过接入ISP连接到互联网，接入ISP必须互联。</strong><br>第一层ISP：节点少，完成全球范围内的覆盖，通过Tier或IXP互相连接。<br>第二层ISP：区域性的可接入第一层ISP也可连接第二层ISP<br>第三层ISP：local ISP，把终端接进来。</p><h5 id="ISP之间的连接："><a href="#ISP之间的连接：" class="headerlink" title="ISP之间的连接："></a>ISP之间的连接：</h5><p>1.POP：高层ISP接入低层ISP<br>2.对等接入：两个对等的ISP互联<br>3.IXP：多个ISP互联互通<br>4.ICP部署自己的专网同时与各级ISP连接</p><h3 id="1-6分组延时、丢失和吞吐量"><a href="#1-6分组延时、丢失和吞吐量" class="headerlink" title="1.6分组延时、丢失和吞吐量"></a>1.6分组延时、丢失和吞吐量</h3><h5 id="分组丢失和延时的原因："><a href="#分组丢失和延时的原因：" class="headerlink" title="分组丢失和延时的原因："></a>分组丢失和延时的原因：</h5><p>分组在通过链路时要排队,队满会被丢弃</p><h5 id="四种分组延时："><a href="#四种分组延时：" class="headerlink" title="四种分组延时："></a>四种分组延时：</h5><p>1.节点处理延时：查路由表等操作（微秒）<br>2.排队延时：在输出链路上等待传输的时间（取决于拥塞程度-流量强度）a=分组到达队列的平均速率，流量强度I=<strong>La/R</strong>，流量强度趋近于1时通行时间无限大，等于0时最小<br>3.传输延时：R=链路带宽，L=分组长度，将分组发送到链路上的时间=<strong>L/R</strong>（低速率的链路会很大微秒到毫秒）<br>4.传播延时：d=物理链路的长度，s=在媒体上的传播速度，传播延时=<strong>d/s</strong>（几微秒到几百毫秒）</p><h5 id="Internet的延时和路由："><a href="#Internet的延时和路由：" class="headerlink" title="Internet的延时和路由："></a>Internet的延时和路由：</h5><p>ICMP互联网控制报文协议 目的IP+TTL（生存时间，第几跳被杀掉然后给源IP发送ICMP报文）+数据<br>RTT（round trip time）往返延迟</p><h5 id="分组丢失："><a href="#分组丢失：" class="headerlink" title="分组丢失："></a>分组丢失：</h5><p>丢失的分组可能会被前一个节点或源端系统重传，或根本不重传。</p><h5 id="吞吐量："><a href="#吞吐量：" class="headerlink" title="吞吐量："></a>吞吐量：</h5><p>单位时间内从源主机向目标主机放出的有效的bit的数量<br>瞬间吞吐量，平均吞吐量(取决于最小的管道)<strong>瓶颈链路</strong>限制了端到端吞吐量。</p><h3 id="1-7协议层次及服务模型"><a href="#1-7协议层次及服务模型" class="headerlink" title="1.7协议层次及服务模型"></a>1.7协议层次及服务模型</h3><h5 id="协议层次："><a href="#协议层次：" class="headerlink" title="协议层次："></a>协议层次：</h5><p><strong>计算机网络是一个复杂的系统</strong><br>功能复杂：数字信号的物理信号承载、点到点、路由、rdt、进程区分、应用等<br>构成元素复杂：主机、路由器、链路、应用、协议、软硬件<br><strong>采用分层的方法来组织实现</strong><br>把复杂的功能分为一个个功能明确的层次，每一层通过层间接口向上层提供服务。<br>通过下层提供的服务实现<strong>协议</strong>（水平的）从而更好地服务上层</p><blockquote><p>服务：低层实体向上层实体提供他们之间的通信的能力（垂直的）<br>服务用户/提供者，服务访问点SAP（区分不同的上层用户）<br>原语（primitive）：<strong>函数</strong>服务提供者通过原语告诉用户我向你提供什么服务</p></blockquote><h5 id="服务类型："><a href="#服务类型：" class="headerlink" title="服务类型："></a>服务类型：</h5><p>面向连接的服务（TCP）：两个用户在使用下层所提供的服务之前要有一个握手的关系要为之后的通信做好准备。<br>无连接的服务（UDP）：两个应用进程在通信前不握手，直接发送信息。</p><blockquote><p>服务和协议的差别：服务是垂直的，协议是水平的。<br>服务和协议的关系：本层协议的实现要借助于下层服务，目的是为了向上层提供更好地服务</p></blockquote><h5 id="数据单元（DU）："><a href="#数据单元（DU）：" class="headerlink" title="数据单元（DU）："></a>数据单元（DU）：</h5><p>SAP：层间接口，SDU（服务数据单元）：上一层交给的要传输的数据，ICI（接口控制信息）：更顺利的穿过层间接口，IDU=SDU+ICI，<strong>PDU（协议数据单元）</strong>：对等层协议交换，SDU+第n层头部信息</p><h5 id="分层处理的好处："><a href="#分层处理的好处：" class="headerlink" title="分层处理的好处："></a>分层处理的好处：</h5><p>概念化：结构清晰，便于标识网络组件以及描述其相互关系。<br>结构化：模块化更易于维护和系统升级，改变某一层不影响其他层。<br><strong>分层有害之处：</strong>一层层实现的效率低</p><h5 id="互联网协议栈："><a href="#互联网协议栈：" class="headerlink" title="互联网协议栈："></a>互联网协议栈：</h5><h6 id="应用层："><a href="#应用层：" class="headerlink" title="应用层："></a>应用层：</h6><p>应用进程通过TCP交到传输层传输给对方的TCP交给对方的应用进程。应用进程就可以通过传输层完成应用报文的交互从而实现想干的事。<br><strong>常见协议：</strong>FTP、SMTP、HTTP<br><strong>协议数据单元：</strong>报文（message）</p><h6 id="传输层："><a href="#传输层：" class="headerlink" title="传输层："></a>传输层：</h6><p>借助于网络层主机到主机的服务，完成进程到进程的区分。把网络层提供的不可靠的服务变成可靠的。<br><strong>常见协议：</strong>TCP、UDP<br><strong>协议数据单元：</strong>报文段（segment）：TCP段、UDP段</p><h6 id="网络层："><a href="#网络层：" class="headerlink" title="网络层："></a>网络层：</h6><p>在链路层提供的相邻两点的数据传输的基础之上，传输以分组为单位的<strong>端到端</strong>（源主机到目标主机）的数据传输。（E2E）<br><strong>常见协议：</strong>IP协议、路由选择协议<br><strong>协议数据单元：</strong>分组（packet），如果<strong>无连接方式（IP网络）</strong>：数据报（datagram）</p><h6 id="链路层："><a href="#链路层：" class="headerlink" title="链路层："></a>链路层：</h6><p>在物理层提供的服务的基础之上，在相邻的两点之间传输以帧为单位的数据。（P2P）<br><strong>常见协议：</strong>PPP，以太网协议、WLAN协议<br><strong>协议数据单元：</strong>帧（frame）</p><h6 id="物理层："><a href="#物理层：" class="headerlink" title="物理层："></a>物理层：</h6><p>把数字信号转换成物理信号承载在媒体之上，从一点传到相邻的另一点，对方的物理层再把物理信号转换成数字信号。（以bit为单位）<br><strong>协议数据单元：</strong>位（bit）</p><h5 id="ISO-OSI参考模型（七层模型）："><a href="#ISO-OSI参考模型（七层模型）：" class="headerlink" title="ISO/OSI参考模型（七层模型）："></a>ISO/OSI参考模型（七层模型）：</h5><p>在应用层和传输层之间加了表示层（表示转换）、会话层（会话管理）</p><h5 id="封装和解封装："><a href="#封装和解封装：" class="headerlink" title="封装和解封装："></a>封装和解封装：</h5><p>在源主机进行封装传输，到某个路由器进行下三层（物理层，链路层，网络层）的解封装与封装，到某个交换机进行下两层的解封装和封装，到目标主机进行全部的解封装</p><h2 id="第二章-应用层"><a href="#第二章-应用层" class="headerlink" title="第二章 应用层"></a>第二章 应用层</h2><blockquote><p>目标:掌握计算机网络应用的原理,网络应用协议的概念和实现方面.(传输层的服务模型,客户-服务器模式,对等模式)了解网络应用的实例,互联网流行的应用层协议.(HTTP,FTP,SMTP,DNS)编程</p></blockquote><h3 id="2-1应用层协议原理"><a href="#2-1应用层协议原理" class="headerlink" title="2.1应用层协议原理"></a>2.1应用层协议原理</h3><blockquote><p>一些网络应用的例子:E-mail,Web,文本信息,远程登陆,P2P文件共享,即时通信,多用户网络游戏,流媒体(youtube),Internet电话,实时电视会议,社交网络,搜索</p></blockquote><h5 id="网络应用的体系架构"><a href="#网络应用的体系架构" class="headerlink" title="网络应用的体系架构:"></a>网络应用的体系架构:</h5><p>1.客户端-服务器(C/S)模式<br>服务器一直运行且固定IP,客户端主动与服务器通信且IP不固定.<strong>问题</strong>可扩展性差,服务器宕机服务就无法享受.<br>2.P2P结构<br>几乎没有一直运行的服务器,任意端系统之间可以进行通信,每一个节点既是客户端也是服务器,参与的主机间歇性连接且可以改变IP地址,自扩展性.<strong>问题</strong>管理起来困难.<br>3.混合体<br>Napster:主机在中心服务器上注册其资源,主机向中心服务器查询资源位置,通过P2P传输</p><h5 id="进程通信"><a href="#进程通信" class="headerlink" title="进程通信:"></a>进程通信:</h5><p><strong>进程</strong>在主机上运行的应用进程<br>发起通信的进程叫客户端进程,等待连接的进程叫服务器进程.同一主机内,使用进程间通信机制通信.不同主机,通过交换报文来通信.<br><strong>分布式进程通信需要解决的问题</strong>1.进程标示和寻址问题2.传输层-应用层如何提供服务3.如何使用传输层提供的服务,实现应用进程之间的报文交换,实现应用,定义协议.<br>问题一:进程用IP地址和端口号标示<br>问题二:传输层提供的服务-需要穿过层间的信息(要传输的报文,源地址,目标地址),传输层实体根据信息进行报文段的封装.<br>TCP socket,用一个整数表示两个实体之间的通信关系(四元组)具有本地意义,唯一指定一个会话.<br>UDP socket,用一个整数表示本应用实体的标示,代表本地的IP和端口不代表一个会话,但传输时必须提供对方的IP和端口<br>问题三:定义应用层协议,应用协议只是应用的一部分.公开协议/私有协议.<br>传输层向应用层提供的服务的性能指标:可靠性,延迟,吞吐量,安全性<br>互联网传输层提供的服务:TCP(可靠的,流量控制发送方不会淹没接收方,拥塞控制抑制发送方,不能提供时间保障,最小吞吐量保障,安全保障)/UDP(不可靠的,没有流量控制等,<strong>省时</strong>)<br>因为TCP和UDP都不安全,跑在TCP之上的SSL提供了安全性(提供了私密性,完整性,端到端的鉴别)</p><h3 id="2-2Web-and-HTTP"><a href="#2-2Web-and-HTTP" class="headerlink" title="2.2Web and HTTP"></a>2.2Web and HTTP</h3><h5 id="Web："><a href="#Web：" class="headerlink" title="Web："></a>Web：</h5><p>Web页由一些对象组成。对象可以是HTML文件、JPEG图像等。通过URL对每个对象进行引用，<strong>URL格式：Prot（协议名）：//user（用户）:psw（口令）@<a href="http://www.someschool.edu(主机名)/someDept%EF%BC%88%E8%B7%AF%E5%BE%84%E5%90%8D%EF%BC%89/pic.gif:port%EF%BC%88%E7%AB%AF%E5%8F%A3%EF%BC%89">www.someSchool.edu（主机名）/someDept（路径名）/pic.gif:port（端口）</a></strong></p><h5 id="HTTP："><a href="#HTTP：" class="headerlink" title="HTTP："></a>HTTP：</h5><p>超文本传输协议。先建立TCP连接，端口号为80，浏览器向web服务器发送http报文，然后受到回复。HTTP是无状态的，服务器并不维护关于客户的任何信息</p><h6 id="非持久HTTP："><a href="#非持久HTTP：" class="headerlink" title="非持久HTTP："></a>非持久HTTP：</h6><p>客户端向服务器发送连接建立请求，服务器在80端口上等待请求，接受连接并通知客户端，客户端向TCP连接的套接字发送HTTP请求报文，HTTP服务器收到报文并向客户端发送响应报文，客户端收到响应报文。<br>往返时间RTT：一个小分组从客户端到服务器再回到客户端的时间。一个RTT用来发起TCP连接，一个RTT用来HTTP请求并等待HTTP响应<br>非持久的缺点：每个对象都要两个RTT的时间</p><h6 id="持久HTTP："><a href="#持久HTTP：" class="headerlink" title="持久HTTP："></a>持久HTTP：</h6><p>服务器在发送响应后仍保持TCP连接。<br>非流水方式：客户端只能在收到前一个响应之后才能发出请求。<br>流水方式：客户端遇到一个引用对象就立即产生一个请求。</p><h6 id="HTTP请求报文："><a href="#HTTP请求报文：" class="headerlink" title="HTTP请求报文："></a>HTTP请求报文：</h6><p>请求行（GET、POST、HEAD命令）+首部行</p><h6 id="提交表单输入："><a href="#提交表单输入：" class="headerlink" title="提交表单输入："></a>提交表单输入：</h6><p>POST方式、URL方式</p><h6 id="HTTP响应报文："><a href="#HTTP响应报文：" class="headerlink" title="HTTP响应报文："></a>HTTP响应报文：</h6><p>状态行（协议版本，状态码，相应状态信息）+首部行+数据</p><h6 id="用户-服务器状态：cookie"><a href="#用户-服务器状态：cookie" class="headerlink" title="用户-服务器状态：cookie"></a>用户-服务器状态：cookie</h6><p>四个组成部分：<br>1、在HTTP响应报文中有一个cookie的首部行<br>2、在HTTP请求报文中有一个cookie的首部行<br>3、在用户端系统中保留有一个cookie文件<br>4、在web站点有一个后端数据库<br>可以用户验证，购物车，推荐，用户状态</p><h6 id="Web缓存（代理服务器）："><a href="#Web缓存（代理服务器）：" class="headerlink" title="Web缓存（代理服务器）："></a>Web缓存（代理服务器）：</h6><p>用户通过缓存访问Web。降低客户端的请求响应时间，可以减少一个机构内部网络与Internet接入链路上的流量，可以使较弱的ICP也能够有效提供内容</p><h6 id="条件GET方法："><a href="#条件GET方法：" class="headerlink" title="条件GET方法："></a>条件GET方法：</h6><p>如果缓存器中的对象拷贝是最新的，就不要发送对象</p><h3 id="2-3FTP"><a href="#2-3FTP" class="headerlink" title="2.3FTP"></a>2.3FTP</h3><p>文件传输协议。客户端包括用户接口，本地文件接口。服务器端口为21.<br><strong>控制连接与数据连接分开</strong>FTP客户端与FTP服务器通过21端口联系，并使用TCP为传输协议。客户端通过控制连接获得身份认证。客户端通过控制连接发送命令。服务器收到命令，跟客户端的20端口主动建立数据连接，并传输文件<br><strong>有状态</strong></p><h3 id="2-4Email，SMTP，POP3，IMAP"><a href="#2-4Email，SMTP，POP3，IMAP" class="headerlink" title="2.4Email，SMTP，POP3，IMAP"></a>2.4Email，SMTP，POP3，IMAP</h3><h5 id="电子邮件"><a href="#电子邮件" class="headerlink" title="电子邮件"></a>电子邮件</h5><p>三个组成部分：用户代理，邮件服务器，简单邮件传输协议（SMTP）</p><h6 id="用户代理"><a href="#用户代理" class="headerlink" title="用户代理"></a>用户代理</h6><p>撰写邮件的软件Outlook</p><h6 id="邮件服务器"><a href="#邮件服务器" class="headerlink" title="邮件服务器"></a>邮件服务器</h6><p>守候在25端口，用SMTP协议发送邮件，接受邮件到客户端邮箱（用邮件拉取协议）</p><h6 id="SMTP协议"><a href="#SMTP协议" class="headerlink" title="SMTP协议"></a>SMTP协议</h6><p>使用TCP在客户端和服务器之间传送报文，端口号为25.传输的三个阶段：握手，传输报文，关闭。持久连接，要求报文为七位ASCII编码，HTTP是拉，SMTP是推<br><strong>邮件报文格式</strong>首部行（To，From，CC）+主体<br>MIME：多媒体扩展（使能传输中文等）</p><h6 id="邮件访问协议："><a href="#邮件访问协议：" class="headerlink" title="邮件访问协议："></a>邮件访问协议：</h6><p>从服务器访问协议（拉）<br>POP3：用户确认阶段 客户端命令（user，pass），服务器响应（OK，ERR）。事务处理阶段，客户端向服务器发出指令。无状态的<br>IMAP（提供远程目录维护）服务器将每个报文与一个文件夹联系。有状态的。<br>HTTP</p><h3 id="2-5DNS"><a href="#2-5DNS" class="headerlink" title="2.5DNS"></a>2.5DNS</h3><p>域名解析系统</p><h5 id="DNS的必要性："><a href="#DNS的必要性：" class="headerlink" title="DNS的必要性："></a>DNS的必要性：</h5><p>IP地址标识主机、路由器。但IP地址不好记，所以人类用户可以使用字符串<strong>域名</strong>交给DNS交换成IP地址。</p><h5 id="DNS的总体思路和目标"><a href="#DNS的总体思路和目标" class="headerlink" title="DNS的总体思路和目标"></a>DNS的总体思路和目标</h5><p>主要思路：<br>分层的、基于域的命名机制<br>若干分布式的数据库完成名字到IP的转换<br>运行在UDP之上端口号为53的应用服务<br>核心的Internet功能，但以应用层协议实现<br>主要目标：<br>实现主机域名-IP地址的转换<br>主机别名到规范名字的转换<br>邮件服务器别名到邮件服务器的正规名字的转换<br>负载均衡</p><h5 id="DNS需要解决的问题："><a href="#DNS需要解决的问题：" class="headerlink" title="DNS需要解决的问题："></a>DNS需要解决的问题：</h5><h6 id="1-如何命名设备"><a href="#1-如何命名设备" class="headerlink" title="1.如何命名设备"></a>1.如何命名设备</h6><p>用有意义的字符串，分层化命名<br>DNS域名结构：<br>采用层次树状结构命名<br>Internet根被划分为几百个顶级域。通用的：.com，.edu等 国家的.cn等。每个子域下面可划分为若干个子域。树叶是主机。<br>根有十几个<br><strong>域名</strong>：从本域往上走直到树根<br>域名管理：<br>一个域管理其下的子域<br>域与物理网络无关：<br>域遵从组织界限。一个域的主机可以不在一个网络。</p><h6 id="2-如何完成名字到IP的转换"><a href="#2-如何完成名字到IP的转换" class="headerlink" title="2.如何完成名字到IP的转换"></a>2.如何完成名字到IP的转换</h6><p>分布式的数据库维护和响应名字查询<br>将DNS名字空间划分为互不相交的区域，每个区域都是树的一部分。每个区域都有一个名字服务器，名字服务器允许被放置在区域外<br>TDL服务器：顶级域服务器，负责顶级域名<br>区域名字服务器维护资源记录（域名-IP的映射关系）格式：域名+生存时间+Class类别+Value值+TYPE类别<br>TYPE=：<br>A name为主机，value为IP地址<br>NS name为域名，value为该域名的权威服务器的域名<br>CNAME 那么为规范名字的别名，value为规范名字<br>MX value为name对于的邮件服务器的名字<br>TTL：<br>生存时间，决定了资源记录应当从缓存中删除的时间<br>DNS工作过程：<br>应用调用解析器<br>解析器作为客户向Name Server发出查询报文<br>Name Server返回响应报文<br>递归查询：往上找直到根服务器，会使根服务器负担太重<br>迭代查询：根服务器返回下一个NS的地址<br>DNS协议，报文<br>DNS协议：查询和响应报文的报文格式相同<br>报文首部：标识符（ID）16位+flags</p><h6 id="3-如何维护"><a href="#3-如何维护" class="headerlink" title="3.如何维护"></a>3.如何维护</h6><p>增加或删除一个域，需要在域名系统中做哪些工作<br>新增一个域：<br>在上级域的名字服务器中增加两条记录，指向这个新增的子域的域名和域名服务器的地址。在新增的子域的名字服务器上运行名字服务器，负责本域的名字解析</p><h3 id="2-6P2P应用"><a href="#2-6P2P应用" class="headerlink" title="2.6P2P应用"></a>2.6P2P应用</h3><h5 id="C-S-VS-P2P"><a href="#C-S-VS-P2P" class="headerlink" title="C/S VS P2P"></a>C/S VS P2P</h5><h6 id="文件分发："><a href="#文件分发：" class="headerlink" title="文件分发："></a>文件分发：</h6><p>C/S:<br>都是由服务器发送给peer，服务器必须顺序传输N个文件拷贝。每个客户端必须下载一个文件拷贝。文件过多时服务器上载带宽成为瓶颈。文件少时客户端的下载能力成为瓶颈。下载时间线性增加<br>P2P：<br>服务器最少上载一份拷贝，每个客户端必须下载一个拷贝，所有客户端总体下载量NF。下载时间平缓增加。</p><blockquote><p>overlay邻居间的文件的上下载的协作关系<br>非结构化P2P：集中式目录（每个结点向目录服务器注册）、完全分布式（每个节点构建一个overlay，邻居向邻居发起查询）、混合体（每个节点属于一个组且存在组长，组长和组长之间相当于邻居，组长对于组员就是目录服务器）<br>DHT（结构化P2P）：每个节点之间可以构成环、树的关系</p></blockquote><h3 id="2-7CDN"><a href="#2-7CDN" class="headerlink" title="2.7CDN"></a>2.7CDN</h3><h5 id="多媒体流化服务："><a href="#多媒体流化服务：" class="headerlink" title="多媒体流化服务："></a>多媒体流化服务：</h5><p>DASH（动态自适应流化技术）<br>服务器将视频文件分割成多个块，每个块独立储存。告示文件会提供不同块的URL。客户端先获取告示文件，周期性地测量服务器到客户端地带宽，查询告示文件，在一个时刻请求一个块，HTTp头部指定字节范围，如果带宽足够选择码率最大的视频块</p><h5 id="CDN："><a href="#CDN：" class="headerlink" title="CDN："></a>CDN：</h5><p>全网部署缓存节点，存储服务内容，就近为用户提供服务。<br>enter deep：将CDN服务器深入到许多接入网<br>bring home：部署在少数关键位置，如将服务器簇安装在POP附近</p><h3 id="2-8TCP套接字（Socket）编程"><a href="#2-8TCP套接字（Socket）编程" class="headerlink" title="2.8TCP套接字（Socket）编程"></a>2.8TCP套接字（Socket）编程</h3><p>应用进程使用传输层提供的服务才能交换报文实现应用协议</p><blockquote><p>套接字：应用进程与端到端传输协议（TCP或UDP）之间的门户</p></blockquote><blockquote><p>目标：学习如何构建能借助sockets进行通信的C/S应用程序</p></blockquote><p>TCP提供可靠的、字节流的服务<br>服务器：<br>服务器先运行，创建欢迎socket，和本地端口绑定，在欢迎socket上阻塞式等待接收用户的连接<br>客户端：<br>客户端主动和服务器建立连接，创建客户端本地套接字绑到本地port上，指定服务器进程的IP地址和端口号，与服务器进程连接，连接API调用有效时，客户端与服务器建立了TCP连接。<br>客户端连接请求到来时<br>服务器接受来自用户端的请求，解除阻塞式等待，返回一个新的socket与客户端通信。允许服务器与多个客户端通信。使用源IP和源端口来区分不同的客户端</p><h5 id="结构体："><a href="#结构体：" class="headerlink" title="结构体："></a>结构体：</h5><p><strong>sockaddr_in</strong>:放IP、端口<br>sin_family-&gt;地址簇<br>sin_port-&gt;port<br>sin_addr-&gt;IP地址<br>sin_zero[8]-&gt;对其<br><strong>host_ent</strong>:域名解析函数，输入域名输出IP地址<br>*h_name-&gt;主机域名<br>**h_aliases-&gt;主机别名<br>h_length-&gt;地址长度<br>**h_addr_list[0]-&gt;IP列表</p><h3 id="2-9UDP套接字编程"><a href="#2-9UDP套接字编程" class="headerlink" title="2.9UDP套接字编程"></a>2.9UDP套接字编程</h3><p>没有握手，发送端在每一个报文中明确地指定目标的IP地址和端口号，服务器必须从收到的分组中提取出发送端的IP地址和端口号，<br>UDP提供不可靠的服务</p><h2 id="第三章-传输层"><a href="#第三章-传输层" class="headerlink" title="第三章 传输层"></a>第三章 传输层</h2><h2 id="第四章-网络层：数据平面"><a href="#第四章-网络层：数据平面" class="headerlink" title="第四章 网络层：数据平面"></a>第四章 网络层：数据平面</h2><h2 id="第五章-网络层：控制平面"><a href="#第五章-网络层：控制平面" class="headerlink" title="第五章 网络层：控制平面"></a>第五章 网络层：控制平面</h2><h2 id="第六章-数据链路层和局域网"><a href="#第六章-数据链路层和局域网" class="headerlink" title="第六章 数据链路层和局域网"></a>第六章 数据链路层和局域网</h2>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>test</title>
      <link href="/2023/04/07/test/"/>
      <url>/2023/04/07/test/</url>
      
        <content type="html"><![CDATA[<p>sadsadas</p>]]></content>
      
      
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title>关于</title>
      <link href="/about/index.html"/>
      <url>/about/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/css/custom.css"/>
      <url>/css/custom.css</url>
      
        <content type="html"><![CDATA[/* 页脚与头图透明 */#footer {    background: transparent !important;  }  #page-header {    background: transparent !important;  }    /* 白天模式遮罩透明 */  #footer::before {    background: transparent !important;  }  #page-header::before {    background: transparent !important;  }    /* 夜间模式遮罩透明 */  [data-theme="dark"] #footer::before {    background: transparent !important;  }  [data-theme="dark"] #page-header::before {    background: transparent !important;  }/* 翻页按钮居中 */#pagination {    width: 100%;    margin: auto;  }/* 一级菜单居中 */#nav .menus_items {    position: absolute !important;    width: fit-content !important;    left: 50% !important;    transform: translateX(-50%) !important;  }  /* 子菜单横向展示 */  #nav .menus_items .menus_item:hover .menus_item_child {    display: flex !important;  }  /* 这里的2是代表导航栏的第2个元素，即有子菜单的元素，可以按自己需求修改 */  .menus_items .menus_item:nth-child(2) .menus_item_child {    left: -125px;  }  :root {    --trans-light: rgba(255, 255, 255, 0.88);    --trans-dark: rgba(25, 25, 25, 0.88);    --border-style: 1px solid rgb(169, 169, 169);    --backdrop-filter: blur(5px) saturate(150%);  }    /* 首页文章卡片 */  #recent-posts > .recent-post-item {    background: var(--trans-light);    backdrop-filter: var(--backdrop-filter);    border-radius: 25px;    border: var(--border-style);  }    /* 首页侧栏卡片 */  #aside-content .card-widget {    background: var(--trans-light);    backdrop-filter: var(--backdrop-filter);    border-radius: 18px;    border: var(--border-style);  }    /* 文章页、归档页、普通页面 */  div#post,  div#page,  div#archive {    background: var(--trans-light);    backdrop-filter: var(--backdrop-filter);    border: var(--border-style);    border-radius: 20px;  }    /* 导航栏 */  #page-header.nav-fixed #nav {    background: rgba(255, 255, 255, 0.75);    backdrop-filter: var(--backdrop-filter);  }    [data-theme="dark"] #page-header.nav-fixed #nav {    background: rgba(0, 0, 0, 0.7) !important;  }    /* 夜间模式遮罩 */  [data-theme="dark"] #recent-posts > .recent-post-item,  [data-theme="dark"] #aside-content .card-widget,  [data-theme="dark"] div#post,  [data-theme="dark"] div#archive,  [data-theme="dark"] div#page {    background: var(--trans-dark);  }      /* 夜间模式页脚页头遮罩透明 */  [data-theme="dark"] #footer::before {    background: transparent !important;  }  [data-theme="dark"] #page-header::before {    background: transparent !important;  }    /* 阅读模式 */  .read-mode #aside-content .card-widget {    background: rgba(158, 204, 171, 0.5) !important;  }  .read-mode div#post {    background: rgba(158, 204, 171, 0.5) !important;  }    /* 夜间模式下的阅读模式 */  [data-theme="dark"] .read-mode #aside-content .card-widget {    background: rgba(25, 25, 25, 0.9) !important;    color: #ffffff;  }  [data-theme="dark"] .read-mode div#post {    background: rgba(25, 25, 25, 0.9) !important;    color: #ffffff;  }]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>友链</title>
      <link href="/link/index.html"/>
      <url>/link/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>电影</title>
      <link href="/movies/index.html"/>
      <url>/movies/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/css/progress_bar.css"/>
      <url>/css/progress_bar.css</url>
      
        <content type="html"><![CDATA[.pace {    -webkit-pointer-events: none;    pointer-events: none;    -webkit-user-select: none;    -moz-user-select: none;    user-select: none;    z-index: 2000;    position: fixed;    margin: auto;    top: 4px;    left: 0;    right: 0;    height: 8px;    border-radius: 8px;    width: 7rem;    background: #eaecf2;    border: 1px #e3e8f7;    overflow: hidden}.pace-inactive .pace-progress {    opacity: 0;    transition: .3s ease-in}.pace .pace-progress {    -webkit-box-sizing: border-box;    -moz-box-sizing: border-box;    -ms-box-sizing: border-box;    -o-box-sizing: border-box;    box-sizing: border-box;    -webkit-transform: translate3d(0, 0, 0);    -moz-transform: translate3d(0, 0, 0);    -ms-transform: translate3d(0, 0, 0);    -o-transform: translate3d(0, 0, 0);    transform: translate3d(0, 0, 0);    max-width: 200px;    position: absolute;    z-index: 2000;    display: block;    top: 0;    right: 100%;    height: 100%;    width: 100%;    /* linear-gradient(to right, #3494e6, #ec6ead) */    background: linear-gradient(to right, #43cea2, #3866ca);    animation: gradient 2s ease infinite;    background-size: 200%}.pace.pace-inactive {    opacity: 0;    transition: .3s;    top: -8px}]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>音乐</title>
      <link href="/music/index.html"/>
      <url>/music/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>tags</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
  
</search>
